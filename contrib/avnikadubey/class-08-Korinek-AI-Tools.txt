Korinek AI Tools Paragraph

Within Anton Korinek's 2023 paper "Generative AI for Economic Research: Use Cases and Implications for Economists," the author discusses a myriad of use cases for generative AI, particularly focusing on large language models (LLM) tools, that prove useful in revolutionizing the process of conducting research across 6 main research domains. Korinek's suggestions range from the initial ideation stages of developing a research topic to identifying extensive background literature, preparing written and data analyses, and constructing and formalizing results. Classifying and codifying a multitude of uses, Korinek illuminates both experimental and widely-used techniques, hinting to his audience the realm of capabilities available through LLM interfaces and urging his readers to use his suggestions as simply a baseline off of which one can explore. After reading through Korinek's detailed explanations of micro-tasks conductible through generative AI, I've streamlined his extensive list of suggestions and have summarized a few key techniques I hope to integrate into my personal research process to best accommodate the conduction of my topic: the impact of ESG integration of Emerging Market firms. 

Interwoven throughout his text, Korinek describes AI functionalities as a method to assist in six main domains: ideation and feedback, writing, background research, data analysis, coding, and mathematical derivations. When deciding how to best integrate the use of LLM models, I first asked myself where my weaknesses lie across the six main domains Korinek addresses. As generative AI is meant to be a tool to enhance the quality of research rather than a crutch to rely on, I decided to first use LLM interfaces to assist with the skills I have yet to develop. In fact, Korinek echoes this point by stating that "the most useful attitude towards generative AI is to heed the lessons of comparative advantage [...] [as] [g]enerative AI systems [...] have a comparative advantage in generating content [...] [while] humans have a comparative advantage in evaluating and discriminating content" (Korinek 4). With the comparative advantage perspective in mind, I plan to use LLM models in my research mostly to enhance the code required to produce a quantitative analysis of my research. As LLMs have a unique capability in both writing but also explaining code, I hope to employ generative AI to help as I try to learn the newfound language, debug errors I confront, and suggest improvements to make my code more digestible and inclusive of the tasks I hope to conduct. After creating regressions from my data, I hope to use generative AI to then improve the quality of my coded figures and reformat and classify data. Through the lens of utilizing generative AI for its comparative advantages compared to humans, my first method of employing LLM's would be to enhance my coding ability.

Korinek's individual suggestions regarding the different facets of varying LLMs also can be utilized to fortify research. First, in terms of effective databases to use, Korinet urges his readers to use the most updated and robust versions of LLMs as they have stronger aggregation methods to parse through data and allow for more recency in available data points, allowing for the most high-quality response. When considering Korinet's suggestions, I focused on utilizing the databases of Anthropic's Claude 2, an LLM created by engineers at Johns Hopkins, which possesses about 100k tokens and includes data points from as early as 2023, as well as Meta's LlaMa 2 which utilizes 4k tokens and also incorporates data points from as early as 2023. In consideration of my research topic, given that the timeline during which the data associated with ESG integration is relatively recent, these two LLMs include more results tied to my research topic, allowing for more nuanced responses given the newfound availability of ESG-related data procured over the past five years. 
