Korinek AI Tools Paragraph

Within Anton Korinek's 2023 paper "Generative AI for Economic Research: Use Cases and Implications for Economists," the author discusses a myriad of use cases for generative AI, particularly focusing on large language models (LLM) tools, that prove useful in revolutionizing the process of conducting research across 6 main research domains. Korinek's suggestions range from the initial ideation stages of developing a research topic to identifying extensive background literature, preparing written and data analyses, and constructing and formalizing results. Classifying and codifying a multitude of uses, Korinek illuminates both experimental and widely-used techniques, hinting to his audience the realm of capabilities available through LLM interfaces and urging his readers to use his suggestions as simply a baseline off of which one can explore. After reading through Korinek's detailed explanations of micro-tasks conductible through generative AI, I've streamlined his extensive list of suggestions and have summarized a few key techniques I hope to integrate into my personal research process to best accommodate the conduction of my topic: the impact of ESG integration of Emerging Market firms. 

Interwoven throughout his text, Korinek describes AI functionalities as a method to assist in six main domains: ideation and feedback, writing, background research, data analysis, coding, and mathematical derivations. When deciding how to best integrate the use of LLM models, I first asked myself where my weaknesses lie across the six main domains Korinek addresses. As generative AI is meant to be a tool to enhance the quality of research rather than a crutch to rely on, I decided to first use LLM interfaces to assist with the skills I have yet to develop. In fact, Korinek echoes this point by stating that "the most useful attitude towards generative AI is to heed the lessons of comparative advantage [...] [as] [g]enerative AI systems [...] have a comparative advantage in generating content [...] [while] humans have a comparative advantage in evaluating and discriminating content" (Korinek 4). With the comparative advantage perspective in mind, I plan to use LLM models in my research mostly to enhance the code required to produce a quantitative analysis of my research. As LLMs have a unique capability in both writing but also explaining code, I hope to employ generative AI to help as I try to learn the newfound language, debug errors I confront, and suggest improvements to make my code more digestible and inclusive of the tasks I hope to conduct. After creating regressions from my data, I hope to use generative AI to then improve the quality of my coded figures and reformat and classify data. Through the lens of utilizing generative AI for its comparative advantages compared to humans, my first method of employing LLM's would be to enhance my coding ability.

Korinek's individual suggestions regarding the different facets of varying LLMs also can be utilized to fortify research. First, in terms of effective databases to use, Korinet urges his readers to use the most updated and robust versions of LLMs as they have stronger aggregation methods to parse through data and allow for more recency in available data points, allowing for the most high-quality response. When considering Korinet's suggestions, I focused on utilizing the databases of Anthropic's Claude 2, an LLM created by engineers at Johns Hopkins, which possesses about 100k tokens and includes data points from as early as 2023, as well as Meta's LlaMa 2 which utilizes 4k tokens and also incorporates data points from as early as 2023. In consideration of my research topic, given that the timeline during which the data associated with ESG integration is relatively recent, these two LLMs include more results tied to my research topic, allowing for more nuanced responses given the newfound availability of ESG-related data procured over the past five years. 

In addition to Korinet's recommendations of specific LLMs to utilize, the author also urges readers to utilize these LLMs in order to fortify the more qualitative aspects of research – that is, the written aspects of research proposals and papers. Thus far in my personal research, I have used these LLM's to aide myself in a multitude of processes, including but not limited to brainstorming specific databases to use for the range of countries I’m investigating, evaluating and summarizing findings in prominent papers related to my work, providing feedback for drafts of the written sections of my paper, and even providing counterarguments or identifying gaps in my written responses to help me best fortify my shortcomings. As I continue to read literature surrounding my topic, I hope to employ generative AI to translate any data/documents from BRIC countries, explain unfamiliar vernacular and concepts used in the sustainability and corporate social responsibility space, and track and format references to make the latter half of the project must smoother in assuring proper credit is given. One unique use of LLM’s in my literature review has been asking ChatGPT to identify weaknesses with my dataset and suggest either methods to clean the data or alternative datasets to consider. Korinek largely attests that generative AI’s most robust and well-vetted functionalities pertain to writing and background research; therefore, employing techniques using LLM’s to best ameliorate those facets of one’s project proves extremely useful. 

Ultimately, the quantitative and qualitative uses of generative AI to improve one’s research process are endless; however, there is much to do to guide and teach algorithms of the most appropriate way to inform its human users. Although generative AI has reached a point where human users can capitalize off of its functionality, a mutual relationship exists through which its human users must do their part in informing the LLM when its information was correct and pertinent and when it is harmful. Using the tools listed above, I have already made significant improvements to my research that I would not have been able to do on my own, and I plan on continuing to utilize generative AI to fortify my research going forward. However, as I do so, I will continue to provide feedback to my LLM of choice to make the use of generative AI for others in the future more robust, trustworthy, and well-vetted as this new landscape becomes increasingly popularized within academia.

